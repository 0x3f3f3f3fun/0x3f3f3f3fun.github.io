<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
    <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>DiffBIR: Towards Blind Image Restoration with
        Generative Diffusion Prior</title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-PYVRSFMDRL');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/favicon.svg">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>

    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">DiffBIR: Towards Blind Image Restoration with
                            Generative Diffusion Prior</h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://0x3f3f3f3fun.github.io/">Xinqi Lin</a><sup>1,*</sup>,</span>
                            <span class="author-block">
                                <a href="https://github.com/hejingwenhejingwen">Jingwen He</a><sup>2,*</sup>,</span>
                            <span class="author-block">
                                <a href="https://orcid.org/0000-0001-6277-5635">Ziyan Chen</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://scholar.google.com.tw/citations?user=gkXFhbwAAAAJ&hl=en">Zhaoyang
                                    Lyu</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?user=skQROj8AAAAJ&hl=zh-CN&oi=ao">Ben
                                    Fei</a><sup>2</sup>,
                            </span>
                            <br>
                            <span class="author-block">
                                <a href="http://daibo.info/">Bo Dai</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://wlouyang.github.io/">Wanli Ouyang</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="http://mmlab.siat.ac.cn/yuqiao">Yu Qiao</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="http://xpixel.group/2010/01/20/chaodong.html">Chao Dong</a><sup>1,2</sup>
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup>Shenzhen Institute of Advanced Technology, Chinese
                                Academy of Sciences,</span>
                            <span class="author-block"><sup>2</sup>Shanghai Artificial Intelligence Laboratory</span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- Paper Link. -->
                                <span class="link-block">
                                    <a href="TODO" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv (Comming Soon)</span>
                                    </a>
                                </span>
                                <!-- Code Link. -->
                                <span class="link-block">
                                    <a href="https://github.com/0x3f3f3f3fun/DiffBIR"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>
                                <!-- Video Link. -->
                                <span class="link-block">
                                    <a href="TODO" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-youtube"></i>
                                        </span>
                                        <span>Video (Comming Soon)</span>
                                    </a>
                                </span>
                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero teaser">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <!-- <h2 class="title is-3">Results</h2> -->
                <div class="content has-text-justified">
                    <div style="text-align: center; vertical-align:middle">
                        <img src="./static/images/real50.png" width="800">
                        <p>
                            Comparisons of BSRGAN, Real-ESRGAN+, SwinIR-GAN, and our DiffBIR results on real-life
                            images.
                            DiffBIR is able to (1) generate natural textures; (2) reconstruct semantic regions; (3) not
                            erase small details; (4) overcome severe case.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            We present DiffBIR, which leverages pretrained text-to-image diffusion models for blind
                            image restoration problem. Our framework adopts a two-stage pipeline. In the first stage,
                            we pretrain a restoration module across diversified degradations for improving generalization 
                            capability in real-world scenarios. The second stage leverages the generative ability of
                            latent diffusion models, for achieving realistic image restoration. Specifically, we introduce 
                            an injective modulation sub-network -- LAControlNet for finetuning, while the pre-trained Stable 
                            Diffusion is to maintain its generative ability. Finally, we introduce a controllable module that 
                            allows users to balance quality and fidelity by introducing the latent image guidance in the 
                            denoising process during inference. Extensive experiments have demonstrated its superiority over 
                            state-of-the-art approaches for both blind image super-resolution and blind face restoration tasks 
                            on both synthetic and real-world datasets.
                        </p>
                    </div>
                </div>
            </div>
            <!--/ Abstract. -->

            <!-- Method. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Method</h2>
                    <div class="content has-text-justified">
                        <img src="./static/images/arch.png" width="800">
                        <div align="center">
                            <b>DiffBIR Architecture</b>
                        </div>
                        <p>
                            The two-stage pipeline of DiffBIR: (1) pretrain a Restoration Module (RM) for degradation
                            removal to obtain \(I_{reg}\); (2) leverage fixed Stable Diffusion through our proposed
                            LAControNet for realistic image reconstruction and obtain \(I_{diff}\). RM is trained across
                            diversified degradations in a self-supervised manner, and is fixed during stage-two.
                            LAControlNet
                            contains a parallel module that is partially initialized with the denoiser's checkpoint and
                            has
                            several fusion layers. It uses VAE's encoder to project the \(I_{reg}\) to the latent space,
                            and performs concatenation with the randomly sampled noisy \(z_t\) as the conditioning
                            mechanism.
                        </p>
                    </div>
                </div>
            </div>
            <!--/ Method. -->

            <!-- Paper video. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Video</h2>
                    <div class="publication-video">
                        <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0" frameborder="0"
                            allow="autoplay; encrypted-media" allowfullscreen></iframe>
                    </div>
                </div>
            </div>
            <!--/ Paper video. -->
        </div>
    </section>
    
    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
<pre><code>
@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}
</code></pre>
        </div>
    </section>

    <footer class="footer">
        <div class="container">
            <div class="content has-text-centered">
                <a class="icon-link" href="./static/videos/nerfies_paper.pdf">
                    <i class="fas fa-file-pdf"></i>
                </a>
                <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
                    <i class="fab fa-github"></i>
                </a>
            </div>
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            This website is licensed under a <a rel="license"
                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                                Commons Attribution-ShareAlike 4.0 International License</a>.
                        </p>
                        <p>
                            This means you are free to borrow the <a
                                href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
                            we just ask that you link back to this page in the footer.
                            Please remember to remove the analytics code included in the header of the website which
                            you do not want on your website.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>

</html>
